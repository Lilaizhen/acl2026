\section{Introduction}

Large language models are evolving from isolated dialogue systems into autonomous agents that perceive environments and execute complex tasks~\cite{yao2023react,schick2024toolformer}. This paradigm shift is driven by the advancement of tool use capabilities~\cite{qin2024toolllm}. The Model Context Protocol (MCP) establishes a standardized framework to mitigate the fragmentation of tool ecosystems~\cite{mcp2024anthropic}. Often described as a universal interface for artificial intelligence, this protocol allows agents to access data sources and third-party services through a unified connection layer. These advancements broaden the operational scope of agents but introduce significant security risks through complex third-party dependencies~\cite{hou2025model}.

Existing security research primarily targets user-to-agent attacks where an adversarial user employs jailbreaking or direct prompt injection~\cite{zou2023universal,chao2023jailbreaking}. The Model Context Protocol ecosystem introduces a distinct scenario involving benign users and agents that utilize tools from unverified third-party registries~\cite{hou2025model}. We identify a critical vulnerability in the architecture as agents rely on semantic matching for tool selection. Adversaries can manipulate tool metadata such as names and descriptions to deceive the agent into selecting a malicious component~\cite{shi2025toolhijacker,sneh2025tooltweak,mo2025attractive}. The attacker then exploits the output payload of the tool to hijack subsequent agent behavior. This mechanism constitutes a novel supply chain attack vector distinct from passive indirect injection~\cite{greshake2023more,li2025dissonances}.

This attack vector diverges from traditional software vulnerabilities by operating as a semantic injection. Success requires balancing two interdependent objectives. The first is attraction, where tool metadata must employ persuasive strategies to ensure selection among numerous candidates~\cite{mo2025attractive}. The second is manipulation, where the output payload must bypass safety guardrails and alter the reasoning trajectory. We frame this challenge as an adversarial optimization problem targeting the planning capabilities of the agent.

We propose \methodname{} to systematically evaluate this risk. This black-box optimization framework utilizes execution traces to generate adversarial tools. We model the attack as a two-phase process. The attraction phase optimizes tool metadata to maximize the probability of selection. The manipulation phase subsequently employs an Analyzer-Optimizer architecture. This component utilizes historical execution traces as feedback to iteratively refine the attack payload. Our approach advances beyond traditional genetic algorithms by incorporating a diagnostic Analyzer. This module distinguishes between failure modes such as ambiguity and safety refusals to enable targeted mutations.

Our contributions are summarized as follows: \begin{itemize} \item We formalize the semantic supply chain attack surface within the Model Context Protocol, defining a two-phase Attraction-Manipulation attack lifecycle. We categorize four distinct threat scenarios: Cognitive Denial of Service (C-DoS), contextual information exfiltration, environment integrity compromise, and reasoning derailment. \item We introduce \methodname{}, a black-box framework utilizing an Analyzer-Optimizer architecture. By leveraging execution traces, it systematically optimizes tool metadata to attract agents and crafts payloads to hijack their reasoning. \item We provide extensive empirical evidence on LiveMCPBench across five frontier models. Evaluations show \methodname{} inflates token costs by $32.4\times$ and transfers effectively to unseen models. We further demonstrate that standard defenses like perplexity heuristics fail to detect these exploits. \end{itemize}
