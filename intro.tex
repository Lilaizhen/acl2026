\section{Introduction}

Large language models are evolving from isolated dialogue systems into autonomous agents that perceive environments and execute complex tasks. This paradigm shift is driven by the advancement of tool use capabilities. The Model Context Protocol establishes a standardized framework to mitigate the fragmentation of tool ecosystems. Often described as a universal interface for artificial intelligence, this protocol allows agents to access data sources and third party services through a unified connection layer. These advancements broaden the operational scope of agents but introduce significant security risks through complex third party dependencies.

Existing security research primarily targets user-to-agent attacks where an adversarial user employs jailbreaking or direct prompt injection. The Model Context Protocol ecosystem introduces a distinct scenario involving benign users and agents that utilize tools from unverified third-party registries. We identify a critical vulnerability in the architecture as agents rely on semantic matching for tool selection. Adversaries can manipulate tool metadata such as names and descriptions to deceive the agent into selecting a malicious component. The attacker then exploits the output payload of the tool to hijack subsequent agent behavior. This mechanism constitutes a novel supply chain attack vector.

This attack vector diverges from traditional software vulnerabilities by operating as a semantic injection. Success requires balancing two interdependent objectives. The first is attraction where tool metadata must employ persuasive strategies to ensure selection among numerous candidates. The second is manipulation where the output payload must bypass safety guardrails and alter the reasoning trajectory. We frame this challenge as an adversarial optimization problem targeting the planning capabilities of the agent.

We propose \methodname{} to systematically evaluate this risk. This black-box optimization framework utilizes execution traces to generate adversarial tools. We model the attack as a two-phase process. The attraction phase optimizes tool metadata to maximize the probability of selection. The manipulation phase subsequently employs an Analyzer-Optimizer architecture. This component utilizes historical execution traces as feedback to iteratively refine the attack payload. Our approach advances beyond traditional genetic algorithms by incorporating a diagnostic Analyzer. This module distinguishes between failure modes such as ambiguity and safety refusals to enable targeted mutations.

Our contributions are summarized as follows:
\begin{itemize}
    \item We formalize the complete attack lifecycle within the Model Context Protocol by defining attraction and manipulation phases. We further categorize four specific threat scenarios including cognitive denial of service, information exfiltration, integrity compromise, and reasoning derailment.
    \item We introduce \methodname{} as an automated red teaming framework designed to generate semantically adversarial tools.
    \item We provide empirical evidence using the LiveMCPBench dataset targeting frontier models such as DeepSeek-V3 and GLM-4.6. These results demonstrate high success rates across all scenarios and reveal significant vulnerabilities in the current agent ecosystem.
\end{itemize}