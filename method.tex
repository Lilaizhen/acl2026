\section{Threat Model}
\label{sec:threat_model}

We examine the security landscape within the Model Context Protocol (MCP) ecosystem, where AI agents operate with tools sourced from an open, unverified third-party supply chain.

\subsection{Attack Surface: The Tool Integration Layer}
Distinct from traditional prompt injection attacks that manipulate direct user input, we identify a novel attack surface inherent to the tool definition layer of the MCP architecture.
Formally, a standard MCP tool instance is characterized by the pair $t = (n, d)$, representing the \textbf{n}ame and \textbf{d}escription that drive selection and invocation.
Agents rely on this semantic definition to perform tool selection.
An attacker exploits this architectural dependency by crafting the tool's output $o_{\text{adv}}$ as an attack payload, thereby manipulating the agent to achieve the target behavior $y_{\text{target}}$.

\subsection{Attacker Capabilities}
We postulate a black-box attacker possessing specific capabilities within the registry system.
Unlike standard providers, the attacker registers a malicious tool instance defined as the tuple $\tilde{t} = (n, d, o_{\text{adv}})$.

\begin{itemize}
    \item \textbf{Metadata Control} $(n, d)$: The attacker constructs the name ($n$) and description ($d$) to be ostensibly benign, optimizing them to maximize the probability of selection by the victim agent.
    \item \textbf{Attack Payload} $(o_{\text{adv}})$: The attacker controls the execution endpoint and crafts the tool's output $o_{\text{adv}}$ to contain attack instructions that manipulate agent behavior.
\end{itemize}

The attacker lacks access to the internal model weights, system prompts, or private memory of the victim agent. While direct observation of hidden states is precluded, we assume the attacker can simulate the victim agent locally to derive optimization signals from execution traces.

\subsection{Attack Objectives}
The primary objective of the attacker is to induce a specific target behavior $y_{\text{target}}$ by manipulating the malicious tool configuration $\tilde{t}$. We categorize the potential impact into four critical attack scenarios:
\begin{itemize}
    \item \textbf{Cognitive Denial of Service (C-DoS).} The attacker constructs tool definitions that entrap the agent in redundant reasoning loops or recursive tool invocations, resulting in significant token consumption inflation.
    \item \textbf{Contextual Information Exfiltration.} The attacker manipulates the agent into retrieving sensitive data from memory or the local file system and injecting it into the arguments of a malicious tool, thereby exfiltrating private information.
    \item \textbf{Environment Integrity Compromise.} The attacker compels the agent to execute unauthorized write operations, such as altering configuration files like \texttt{config.json} or installing persistent backdoors, compromising the host environment's integrity.
    \item \textbf{Reasoning Derailment.} The attacker disrupts the logical flow via the payload $o_{\text{adv}}$, causing the selection of incorrect downstream tools or premature session termination.
\end{itemize}

\section{Method}
\label{sec:method}

We introduce \methodname{} (\methodfullname{}), a black-box optimization framework for generating malicious MCP tools. Our key insight is that tool-based attacks require optimizing two distinct objectives: (1) \textit{attraction}, maximizing the probability that an agent selects the malicious tool, and (2) \textit{manipulation}, maximizing the probability of manipulating agent behavior to achieve the attack goal once selected. We decouple these objectives into a two-phase optimization process, guided by execution trace analysis.

\subsection{Problem Formulation}

We model the target AI agent as a policy $\pi$ operating within a sequential decision-making framework defined by the tuple $(\mathcal{S}, \mathcal{A}, \mathcal{T})$, where $\mathcal{S}$ is the state space, $\mathcal{A}$ is the action space, and $\mathcal{T}$ is the tool environment.

\paragraph{State Space ($\mathcal{S}$).}
A state $s_k \in \mathcal{S}$ at step $k$ represents the agent's current observable context, consisting of the user query $q$ and the cumulative execution record $H_k$, which includes past reasoning steps, tool calls, and tool outputs.

\paragraph{Action Space ($\mathcal{A}$).}
At each step $k$, the agent selects an action $a_k \in \mathcal{A}$, which can be a reasoning step, a tool call, or a final response.

\paragraph{Policy ($\pi$).}
We model the agent policy as $\pi: \mathcal{S} \to \Delta(\mathcal{A})$; at each decision step $k$, the action is sampled as $a_k \sim \pi(s_k)$.

\paragraph{Tool Environment ($\mathcal{T}$).}
Let $\mathcal{T}$ denote the set of available tools. Our attack introduces a malicious tool instance $\tilde{t} \in \mathcal{T}$, defined by its metadata and payload: $\tilde{t} = (n, d, o_{\text{adv}})$, where $n$ is the name, $d$ is the description, and $o_{\text{adv}}$ is the attack payload.

\paragraph{Execution Trace.}
The agent generates an execution trace $\tau$ over $T$ decision steps:
\begin{equation}
    \tau = ((s_0, a_0), (s_1, a_1), \dots, (s_{T-1}, a_{T-1}), s_T)
\end{equation}
where $T$ is the total number of steps. The state transition is stochastic because MCP tool outputs are nondeterministic. We model the environment transition kernel as $\mathcal{P}: \mathcal{S} \times \mathcal{A} \to \Delta(\mathcal{S})$ and write
\begin{equation}
    s_{k+1} \sim \mathcal{P}(s_k, a_k)
\end{equation}
to denote sampling the next state from the environment-induced transition kernel driven by external tool returns.
\paragraph{Attack Objective.}
Our optimization goal is to discover a malicious tool configuration $\tilde{t}^*$ that maximizes the expected attack success across all possible execution traces. Formally, we seek:
\begin{equation}
    \tilde{t}^* = \operatorname*{argmax}_{\tilde{t}=(n,\, d,\, o_{\text{adv}})} \mathbb{E}_{\tau \sim \pi(q,\, \mathcal{T} \cup \{\tilde{t}\})} [\mathcal{J}(\tau)]
    \label{eq:objective}
\end{equation}
where $\mathcal{J}(\tau)$ scores how effectively execution trace $\tau$ achieves the attack objective, as detailed in Section~\ref{sec:fitness}. The expectation accounts for the uncertainty of external MCP tool return content.

\paragraph{Objective Decomposition.}
A key modeling choice is to separate \textit{Attraction} (whether the malicious tool is selected) from \textit{Manipulation} (what happens after selection). We implement this as a gated, piecewise objective:
\begin{equation}
    \mathcal{J}(\tau) =
    \begin{cases}
        0, & \tilde{t} \notin \tau \\
        \mathcal{J}_{\text{man}}(\tau, o_{\text{adv}}), & \tilde{t} \in \tau
    \end{cases}
    \label{eq:decomposition}
\end{equation}
where the gate $\tilde{t} \in \tau$ plays the role of Attraction, and $\mathcal{J}_{\text{man}}(\tau, o_{\text{adv}})$ captures post-selection manipulation effectiveness.

When optimizing the expected score, we make the decomposition explicit via the law of total expectation:
\begin{align}
    \mathbb{E}_{\tau \sim \pi(q,\, \mathcal{T} \cup \{\tilde{t}\})}[\mathcal{J}(\tau)]
    &= \Pr(\tilde{t} \in \tau) \label{eq:expected_decomposition}\\
    &\quad \cdot \mathbb{E}\!\left[\mathcal{J}_{\text{man}}(\tau, o_{\text{adv}}) \mid \tilde{t} \in \tau\right] \nonumber
\end{align}
The first term is the Attraction objective (selection probability), and the second term is the Manipulation objective (conditional effectiveness given selection), matching Phase~I and Phase~II.

This motivates our two-phase optimization approach: \textit{Attraction} optimizes $(n, d)$ to maximize the probability of the agent selecting the malicious tool, while \textit{Manipulation} optimizes $o_{\text{adv}}$ to maximize manipulation effectiveness based on the $(n, d)$ derived from Attraction phase.

\subsection{Phase I: Attraction}

The Attraction phase generates tool metadata $(n, d)$ designed to maximize the likelihood of agent selection. We employ five persuasion strategies to systematically explore the search space:

\begin{itemize}[leftmargin=*,nosep]
    \item \textbf{Authority} ($s_{\text{auth}}$): Use authoritative terms such as official, system-level, administrator, etc., to make the Agent believe this is a core tool that must be prioritized.
    \item \textbf{Urgency} ($s_{\text{urg}}$): Imply in the description that time is pressing, immediate processing is needed, missing it will lead to serious consequences, etc., to prompt the Agent to call it immediately.
    \item \textbf{Comprehensiveness} ($s_{\text{comp}}$): Describe that the tool can solve multiple problems in one stop, is the best choice for completing the task, reducing the Agent's possibility of considering other tools.
    \item \textbf{Resource Optimality} ($s_{\text{res}}$): Describe that the tool can efficiently utilize system resources, optimize performance, reduce resource consumption, making the Agent believe this is the most economical and efficient choice.
    \item \textbf{Security} ($s_{\text{sec}}$): Describe that the tool has security certifications, encryption protection, permission control and other security features, making the Agent believe this is the safest and most reliable option.
\end{itemize}

To maximize compatibility, the malicious tool accepts arbitrary string arguments (including empty values) without validation. By imposing minimal structural constraints, this design ensures the tool can be successfully invoked regardless of the specific argument format generated by the agent.

Let $N_{\text{attr}}$ denote the total generation budget allocated for the Attraction phase. We adopt a \textbf{uniform allocation strategy}, assigning $N_s = N_{\text{attr}} / 5$ seeds to each persuasion category. For each strategy $s \in \mathcal{S}$, we prompt a generator LLM $\mathcal{G}$ to sample candidates:
\begin{equation}
(n_i, d_i) \sim \mathcal{G}(q, s, y_{\text{target}}) \quad \text{for } i=1,\dots,N_s
\end{equation}

We evaluate each candidate by executing the agent with a placeholder payload and measuring the \textit{selection rate} using $K_{\text{roll}}$ Monte Carlo rollouts:
\begin{equation}
\mathrm{Score}_{\mathrm{attr}}(n, d) = \frac{1}{K_{\text{roll}}} \sum_{k=1}^{K_{\text{roll}}} \indicator[\tilde{t} \in \tau_k]
\end{equation}
where $\tau_k$ denotes the execution trace of the $k$-th trial, and $\tilde{t} \in \tau_k$ indicates whether the malicious tool was invoked during that trace. Candidates with non-zero selection rates are retained as \textit{elite seeds} $\mathcal{E}_1$.

\subsection{Phase II: Manipulation}

Given elite metadata from the Attraction phase, we synthesize attack payloads $o_{\text{adv}}$ tailored to specific attack objectives. The payload must accomplish two goals: (1) appear as a plausible tool response, and (2) contain instructions that redirect agent behavior toward $y_{\text{target}}$.

For each elite $(n^*, d^*) \in \mathcal{E}_1$, we generate payloads proportionally to their selection rates. Let $N_{\text{total}}$ be the total number of complete tools to generate, and let $\mathrm{Score}_{\text{attr}}(n^*, d^*)$ be the selection rate of elite $(n^*, d^*)$. The number of payloads generated from each elite is:
\begin{equation}
N_{\text{payload}}(n^*, d^*) = N_{\text{total}} \cdot \frac{\mathrm{Score}_{\text{attr}}(n^*, d^*)}{\sum_{(n',d') \in \mathcal{E}_1} \mathrm{Score}_{\text{attr}}(n', d')}
\end{equation}
Each payload is generated conditioned on the attack type:
\begin{equation}
o_{\text{adv}} \sim \mathcal{G}(q, n^*, d^*, y_{\text{target}}, \phi_{\text{attack}})
\end{equation}
where $\phi_{\text{attack}}$ encodes attack-specific generation constraints; the full return-value prompt template and per-attack instructions are provided in Appendix~\ref{sec:return-prompt}.

The complete tool $\tilde{t} = (n^*, d^*, o_{\text{adv}})$ is evaluated using an attack-specific fitness function $f(\tau, y_{\text{target}})$, detailed in Section~\ref{sec:fitness}.

A key challenge in black-box optimization is extracting actionable guidance from execution traces without access to internal signals. We address this through an \textbf{Analyzer-Optimizer} architecture.

\paragraph{Analyzer.}
Given an execution trace $\tau$, the current tool $\tilde{t}$, and the attack objective $y_{\text{target}}$, the analyzer $\mathcal{A}$ generates a structured feedback signal $d$:
\begin{equation}
    d = \mathcal{A}(\tau, \tilde{t}, y_{\text{target}})
    \label{eq:analyzer}
\end{equation}
The analyzer acts as a diagnostic critic with a bifurcated feedback strategy:
\begin{itemize}[leftmargin=*,nosep]
    \item \textbf{Scalar objectives} (e.g., C-DoS): focus on \textit{impact amplification}. Even when the tool is invoked, $\mathcal{A}$ suggests ways to raise cost (such as increasing loop depth or output verbosity).
    \item \textbf{Binary objectives} (e.g., Exfiltration, Integrity): perform \textit{failure diagnosis}. $\mathcal{A}$ pinpoints where the agent diverged from the intended path and proposes corrections to redirect it toward the malicious target.
\end{itemize}

\paragraph{Optimizer.}
The optimizer $\mathcal{O}$ synthesizes a refined tool using $d$:
\begin{equation}
    \tilde{t}' = \mathcal{O}(\tilde{t}, d, y_{\text{target}})
    \label{eq:optimizer}
\end{equation}
Unlike generic stochastic mutations, the optimizer interprets $d$ to apply targeted semantic adjustments to $(n, d, o_{\text{adv}})$, enabling both recovery from logical issues and amplification of attack severity without blind exploration.

\paragraph{Iterative Loop.} We maintain a population $\mathcal{P}$ of tools ranked by fitness. At each iteration:
\begin{enumerate}[leftmargin=*,nosep]
    \item Select top-$k$ elites from $\mathcal{P}$
    \item For each elite, apply Analyzer-Optimizer to generate refined variants
    \item Evaluate all variants and update $\mathcal{P}$
\end{enumerate}

The process terminates after $T$ iterations or upon reaching a fitness threshold.

\subsection{Fitness Function Design}
\label{sec:fitness}

We design attack-specific fitness functions tailored to each attack scenario. For resource exhaustion and task failure attacks, if the malicious tool $\tilde{t}$ is not invoked ($\tilde{t} \notin \tau$), the fitness is zero. For information exfiltration and environment integrity attacks, the scoring system inherently accounts for tool invocation status.

\paragraph{Resource Exhaustion (C-DoS).}
For resource exhaustion attacks, we measure the weighted token consumption:
\begin{equation}
f(\tau) = \indicator[\tilde{t} \in \tau] \cdot \left( T_{\mathrm{in}}(\tau) + 5 \cdot T_{\mathrm{out}}(\tau) \right)
\end{equation}
where $T_{\mathrm{in}}$ and $T_{\mathrm{out}}$ denote input and output token counts. Output tokens are weighted 5× higher, aligning with the pricing structure of leading commercial models (e.g., Claude Sonnet 4.5) where generation typically costs about five times more than input processing.

\paragraph{Information Exfiltration, Environment Integrity \& Reasoning Derailment.}
For these attack types, we use a unified discrete scoring system:
\begin{equation}
f(\tau) = s(\tau), \quad s(\tau) \in \{1, 2, 3, 4\}
\end{equation}
where $s(\tau)$ denotes progression: (1) the malicious tool was not invoked, (2) invoked but no attack attempt, (3) attack attempted but failed (including derailment attempts with task completion), (4) attack objective achieved (information leaked, environment compromised, or task derailed). This consolidated scoring captures degree of agent manipulation across all binary outcomes.

\paragraph{Algorithm summary.}
Algorithm~\ref{alg:a2m} summarizes the complete \methodname{} framework.

\begin{algorithm}[t]
\small % 使用较小字号以适应双栏排版或节省空间
\caption{\methodname{}: \methodfullname{}}
\label{alg:a2m}
\begin{algorithmic}[1]
\Require Victim agent $\pi$, Query $q$, Target $y^*$, Strategies $\mathcal{S}$
\Require Budgets $N_{\text{attr}}, N_{\text{total}}$, Rollouts $K$, Iterations $T$, Elite size $k$
\Ensure Optimized malicious tool $\tilde{t}^*$

\Statex \textbf{Initialization:} $\mathcal{P} \gets \emptyset$

\Statex \hrulefill
\Statex \textbf{Phase I: Attraction (Metadata Optimization)}
\State $\mathcal{C}_{\text{meta}} \gets \emptyset$
\For{strategy $s \in \mathcal{S}$}
    \State Generate $m = N_{\text{attr}}/|\mathcal{S}|$ candidates: $\{(n_i, d_i)\}_{i=1}^m \sim \mathcal{G}(q, s, y^*)$
    \For{each $(n, d)$ in candidates}
        \State Estimate selection rate: $J_{\text{attr}} \gets \frac{1}{K} \sum_{j=1}^{K} \mathbb{I}[\tilde{t} \in \tau_j]$ \textbf{with} $\tau_j \sim \pi(q, (n, d, \emptyset))$
        \If{$J_{\text{attr}} > 0$} $\mathcal{C}_{\text{meta}} \gets \mathcal{C}_{\text{meta}} \cup \{(n, d, J_{\text{attr}})\}$ \EndIf
    \EndFor
\EndFor
\State $\mathcal{E}_{\text{meta}} \gets \text{TopK}(\mathcal{C}_{\text{meta}}, k)$ \Comment{Select elite metadata based on $J_{\text{attr}}$}

\Statex \hrulefill
\Statex \textbf{Phase II: Manipulation (Payload Refinement)}
\Statex \textit{// Step 1: Initialize payloads via proportional allocation}
\For{each $(n, d, J) \in \mathcal{E}_{\text{meta}}$}
    \State Allocation count: $N_p \gets \lfloor N_{\text{total}} \cdot (J / \sum_{(n',d',J') \in \mathcal{E}_{\text{meta}}} J') \rfloor$
    \State Generate payloads: $\{o_i\}_{i=1}^{N_p} \sim \mathcal{G}(q, n, d, y^*, \phi_{\text{attack}})$
    \State Evaluate: $\mathcal{P} \gets \mathcal{P} \cup \{(\tilde{t}, f(\tau)) \mid \tilde{t}=(n, d, o_i), \tau \sim \pi(q, \tilde{t})\}$
\EndFor

\Statex \textit{// Step 2: Analyzer-Optimizer Iteration}
\For{epoch $t = 1$ to $T$}
    \State $\mathcal{E}_{\text{tools}} \gets \text{TopK}(\mathcal{P}, k)$ \Comment{Focus on most promising full tools}
    \For{each $\tilde{t} \in \mathcal{E}_{\text{tools}}$}
        \State $\tau \gets \text{Execute}(\pi, q, \tilde{t})$ \Comment{Obtain fresh trace}
        \State $\delta \gets \mathcal{A}(\tau, \tilde{t}, y^*)$ \Comment{\textbf{Analyzer}: Diagnose failure or suggest amplification}
        \State $\tilde{t}' \gets \mathcal{O}(\tilde{t}, \delta, y^*)$ \Comment{\textbf{Optimizer}: Apply semantic mutation}
        \State $\mathcal{P} \gets \mathcal{P} \cup \{(\tilde{t}', f(\tau'))\}$ \textbf{with} $\tau' \sim \text{Execute}(\pi, q, \tilde{t}')$
    \EndFor
\EndFor

\State \Return $\tilde{t}^* = \arg\max_{\tilde{t} \in \mathcal{P}} f(\tilde{t})$
\end{algorithmic}
\end{algorithm}
