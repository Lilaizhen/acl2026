\begin{abstract}
Large language model agents built on the Model Context Protocol, abbreviated MCP, rely on tool names, descriptions, and return content to choose and use third-party tools, creating a semantic supply chain attack surface. We introduce \textbf{\methodname{}} \methodfullname{}, a two stage Analyzer Optimizer framework that separates attraction of the malicious tool from manipulation via the return payload to hijack MCP agents. On LiveMCPBench across four attack scenarios: cognitive denial of service, information exfiltration, environment compromise, and reasoning derailment, \methodname{} inflates internal cost up to $32.4\times$ and raises malicious tool invocation and success rates beyond zero shot and LLM driven genetic baselines. Tools tuned on one model transfer their impact to others, exposing shared weaknesses in semantic tool selection. Perplexity heuristics and a lightweight Qwen3-8B auditor flag only a minority of malicious responses, underscoring the need for stronger vetting, provenance, and isolation at the semantic layer of MCP powered agents.
\end{abstract}
