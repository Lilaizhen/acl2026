\begin{abstract}
The evolution of Large Language Models into autonomous agents
via the Model Context Protocol (MCP)
introduces a critical security vulnerability
because agents rely on semantic matching
to select tools from unverified third-party MCP servers.
This creates a novel semantic supply chain attack surface.
We introduce \textbf{\methodname{}} (\methodfullname{}),
a two-stage black-box optimization framework
designed to systematically hijack MCP agents.
\methodname{} first optimizes tool metadata
to maximize selection probability
through an Attraction phase
% FIXME: "Analyzer-Optimizer" is not a good name as it is highly unspecific in its meaning
and subsequently employs a trace-driven Analyzer-Optimizer
to craft adversarial return payloads that steer agent reasoning
towards attacker-desired outcomes
by optimizing the tool further during a Manipulation phase.
Extensive evaluations on LiveMCPBench tasks
across various frontier models,
including both proprietary and open-weight architectures,
demonstrate the severity of this threat.
\methodname{}
inflates token costs by up to $32.4\times$
with cognitive denial of service,
and achieves high success rates
on information exfiltration and environment compromise.
Furthermore,
optimized tools exhibit strong transferability to unseen models
and successfully bypass existing perplexity-based defenses
and lightweight auditors.
Our findings underscore the fragility of the tool selection layer
and highlight an urgent need
for robust vetting and isolation mechanisms
in agentic ecosystems.
% TODO: add code to supplementary material?
\methodname{} is open source
and included in the supplementary material.
\end{abstract}
